{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e64a63e4",
   "metadata": {},
   "source": [
    "# CatBoost pipeline (basado en Modelo_prediccion)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67795353",
   "metadata": {},
   "source": [
    "Este notebook carga las funciones de `DataLoader.py`, prepara los datos respetando validación temporal, entrena un `CatBoostRegressor`, evalúa el modelo, calcula elasticidades y exporta las predicciones en formato Kaggle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d65ec540",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imports OK\n"
     ]
    }
   ],
   "source": [
    "# Imports y funciones\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from DataLoader import importar_ventas, preparar_test, agregar_fourier, crear_archivo_kaggle, leer_csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from catboost import CatBoostRegressor, Pool\n",
    "from sklearn.metrics import root_mean_squared_error, mean_absolute_error\n",
    "import os\n",
    "print('Imports OK')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "187421e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa608e24207c4512a380eb8db02ae533",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, layout=Layout(width='auto'), style=ProgressStyle(bar_color='black'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "TypeError",
     "evalue": "preparar_test() missing 2 required positional arguments: 'ventas' and 'FEATURES'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 5\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# 1) Cargar datos (usa las funciones del DataLoader)\u001b[39;00m\n\u001b[0;32m      3\u001b[0m ventas \u001b[38;5;241m=\u001b[39m importar_ventas()\n\u001b[1;32m----> 5\u001b[0m test \u001b[38;5;241m=\u001b[39m \u001b[43mpreparar_test\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mids_test.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mTypeError\u001b[0m: preparar_test() missing 2 required positional arguments: 'ventas' and 'FEATURES'"
     ]
    }
   ],
   "source": [
    "# 1) Cargar datos (usa las funciones del DataLoader)\n",
    "\n",
    "ventas = importar_ventas()\n",
    "\n",
    "test = preparar_test('ids_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b72b2a97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fourier agregado\n"
     ]
    }
   ],
   "source": [
    "# 2) Añadir Fourier (k=2) si se pudo cargar\n",
    "\n",
    "agregar_fourier(ventas, k=2)\n",
    "\n",
    "agregar_fourier(test, k=2)\n",
    "\n",
    "print('Fourier agregado')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0d3bf5a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features definidos: ['subgroup_cod', 'cluster', 'max_price', 'min_price', 'year', 'anual_sin_1', 'anual_cos_1', 'mensual_sin_1', 'mensual_cos_1']\n"
     ]
    }
   ],
   "source": [
    "# 3) Definir features\n",
    "cat_features = ['subgroup_cod','cluster']\n",
    "num_features = ['max_price','min_price','year',\n",
    "                'anual_sin_1','anual_cos_1','mensual_sin_1','mensual_cos_1']\n",
    "\n",
    "# Categóricas (cat_features) → CatBoost las maneja de forma nativa.\n",
    "# Numéricas (num_features) → precios, variables de tiempo, Fourier y lags\n",
    "\n",
    "features = cat_features + num_features\n",
    "print('Features definidos:', features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0d398c6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dates: 2021-01-01 00:00:00 -> 2023-12-02 00:00:00\n",
      "Valid dates: 2023-12-03 00:00:00 -> 2023-12-31 00:00:00\n"
     ]
    }
   ],
   "source": [
    "# 4) Split temporal: evitar leakage\n",
    "if ventas is not None:\n",
    "    max_date = ventas['date'].max()\n",
    "    val_start = max_date - pd.Timedelta(weeks=4)\n",
    "    train = ventas[ventas['date'] < val_start].copy()\n",
    "    valid = ventas[ventas['date'] >= val_start].copy()\n",
    "    print('Train dates:', train['date'].min(), '->', train['date'].max())\n",
    "    print('Valid dates:', valid['date'].min(), '->', valid['date'].max())\n",
    "else:\n",
    "    train = valid = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "08ea8b19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pools creados.\n"
     ]
    }
   ],
   "source": [
    "# 5) Preparar matrices para CatBoost\n",
    "if train is not None and valid is not None and len(valid)>0:\n",
    "    X_train = train[features]\n",
    "    y_train = train['demand']\n",
    "    X_valid = valid[features]\n",
    "    y_valid = valid['demand']\n",
    "    \n",
    "    # Pools\n",
    "    train_pool = Pool(X_train, y_train, cat_features=cat_features)\n",
    "    valid_pool = Pool(X_valid, y_valid, cat_features=cat_features)\n",
    "    print('Pools creados.')\n",
    "else:\n",
    "    train_pool = valid_pool = None\n",
    "    print('No se pudieron crear pools por falta de datos')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2bf7f9f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 3.5553744\ttest: 3.2847950\tbest: 3.2847950 (0)\ttotal: 1.64s\tremaining: 54m 29s\n",
      "100:\tlearn: 2.9293682\ttest: 2.7957041\tbest: 2.7957041 (100)\ttotal: 2m 35s\tremaining: 48m 46s\n",
      "200:\tlearn: 2.7907077\ttest: 2.6686494\tbest: 2.6686494 (200)\ttotal: 5m 26s\tremaining: 48m 42s\n",
      "300:\tlearn: 2.7156669\ttest: 2.6107117\tbest: 2.6107117 (300)\ttotal: 8m 33s\tremaining: 48m 16s\n",
      "400:\tlearn: 2.6673578\ttest: 2.5505584\tbest: 2.5505584 (400)\ttotal: 10m 57s\tremaining: 43m 41s\n",
      "500:\tlearn: 2.6344509\ttest: 2.5019560\tbest: 2.5019560 (500)\ttotal: 13m 33s\tremaining: 40m 33s\n",
      "600:\tlearn: 2.6111725\ttest: 2.4691150\tbest: 2.4691150 (600)\ttotal: 15m 59s\tremaining: 37m 12s\n",
      "700:\tlearn: 2.5929627\ttest: 2.4519621\tbest: 2.4519621 (700)\ttotal: 18m 33s\tremaining: 34m 23s\n",
      "800:\tlearn: 2.5790419\ttest: 2.4383921\tbest: 2.4383921 (800)\ttotal: 21m 6s\tremaining: 31m 36s\n",
      "900:\tlearn: 2.5678437\ttest: 2.4306163\tbest: 2.4306163 (900)\ttotal: 23m 38s\tremaining: 28m 50s\n",
      "1000:\tlearn: 2.5581518\ttest: 2.4251760\tbest: 2.4251760 (1000)\ttotal: 26m 17s\tremaining: 26m 14s\n",
      "1100:\tlearn: 2.5499417\ttest: 2.4183848\tbest: 2.4183848 (1100)\ttotal: 28m 57s\tremaining: 23m 38s\n",
      "1200:\tlearn: 2.5430130\ttest: 2.4142258\tbest: 2.4142258 (1200)\ttotal: 31m 27s\tremaining: 20m 55s\n",
      "1300:\tlearn: 2.5368376\ttest: 2.4106128\tbest: 2.4106128 (1300)\ttotal: 34m 10s\tremaining: 18m 21s\n",
      "1400:\tlearn: 2.5298440\ttest: 2.4078655\tbest: 2.4078598 (1399)\ttotal: 36m 55s\tremaining: 15m 47s\n",
      "1500:\tlearn: 2.5251874\ttest: 2.4062365\tbest: 2.4062365 (1500)\ttotal: 39m 40s\tremaining: 13m 11s\n",
      "1600:\tlearn: 2.5211081\ttest: 2.4040204\tbest: 2.4038966 (1597)\ttotal: 42m 2s\tremaining: 10m 28s\n",
      "1700:\tlearn: 2.5168647\ttest: 2.4019489\tbest: 2.4019489 (1700)\ttotal: 44m 25s\tremaining: 7m 48s\n",
      "1800:\tlearn: 2.5133487\ttest: 2.3995902\tbest: 2.3995902 (1800)\ttotal: 46m 50s\tremaining: 5m 10s\n",
      "1900:\tlearn: 2.5095910\ttest: 2.3986198\tbest: 2.3986198 (1900)\ttotal: 49m 11s\tremaining: 2m 33s\n",
      "1999:\tlearn: 2.5063335\ttest: 2.3972037\tbest: 2.3972037 (1999)\ttotal: 51m 33s\tremaining: 0us\n",
      "\n",
      "bestTest = 2.397203658\n",
      "bestIteration = 1999\n",
      "\n",
      "Modelo entrenado y guardado: catboost_model.cbm\n"
     ]
    }
   ],
   "source": [
    "# 6) Entrenar CatBoost\n",
    "if train_pool is not None and valid_pool is not None:\n",
    "    model = CatBoostRegressor(\n",
    "        iterations=2000, # Número máximo de árboles de decisión\n",
    "        learning_rate=0.05, # Controla cuánto se ajusta el modelo en cada iteración\n",
    "        depth=8, # Profundidad máxima de cada árbol.\n",
    "        loss_function='RMSE', # Función de pérdida que el modelo optimiza\n",
    "        eval_metric='RMSE', # Métrica usada para evaluar el rendimiento en el conjunto de validación durante el entrenamiento\n",
    "        random_seed=42, # Semilla aleatoria para reproducibilidad.\n",
    "        early_stopping_rounds=100, # Si el modelo no mejora la métrica de validación en 100 iteraciones consecutivas, se detiene antes de llegar a iterations.\n",
    "        verbose=100 # Imprime el progreso cada 100 iteraciones.\n",
    "    )\n",
    "    model.fit(train_pool, eval_set=valid_pool)\n",
    "    model.save_model('catboost_model.cbm')\n",
    "    print('Modelo entrenado y guardado: catboost_model.cbm')\n",
    "    \n",
    "else:\n",
    "    model = None\n",
    "    print('No se entrenó el modelo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8c9759ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid RMSE: 2.3972, MAE: 1.7043\n"
     ]
    }
   ],
   "source": [
    "# 7) Evaluación en validación\n",
    "if model is not None and valid is not None:\n",
    "    y_pred_val = model.predict(valid[features])\n",
    "    rmse = root_mean_squared_error(valid['demand'], y_pred_val)\n",
    "    mae  = mean_absolute_error(valid['demand'], y_pred_val)\n",
    "    print(f'Valid RMSE: {rmse:.4f}, MAE: {mae:.4f}')\n",
    "else:\n",
    "    print('No hay evaluación realizada')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "15265ce8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicciones realizadas y archivo kaggle creado (prediccion_kaggle.csv)\n"
     ]
    }
   ],
   "source": [
    "# 8) Predicción sobre test preparado y preparación de Kaggle\n",
    "if model is not None and test is not None:\n",
    "    # Asegurarse que test tenga las mismas columnas\n",
    "    for c in num_features:\n",
    "        if c not in test.columns:\n",
    "            test[c] = np.nan\n",
    "    # Rellenar NANs de price con último precio conocido por grupo\n",
    "    test['date'] = pd.to_datetime(test['date'])\n",
    "    ventas_for_merge = ventas[['date','store_cod','subgroup_cod','mean_price']].copy()\n",
    "    ventas_for_merge['date'] = pd.to_datetime(ventas_for_merge['date'])\n",
    "    ventas_for_merge = ventas_for_merge.sort_values('date')\n",
    "    test['fecha_busqueda'] = test['date'] - pd.DateOffset(weeks=1)\n",
    "    test = pd.merge_asof(\n",
    "        test.sort_values('fecha_busqueda'),\n",
    "        ventas_for_merge.rename(columns={'mean_price':'precio_hist','date':'fecha_ref'}).sort_values('fecha_ref'),\n",
    "        left_on='fecha_busqueda',\n",
    "        right_on='fecha_ref',\n",
    "        by=['store_cod','subgroup_cod'],\n",
    "        direction='backward'\n",
    "    )\n",
    "    \n",
    "    test['mean_price'] = test['precio_hist'].fillna(test['mean_price']).fillna(0)\n",
    "    # ordenar y predecir\n",
    "    test = test.sort_values(['subgroup_cod','store_cod','date']).reset_index(drop=True)\n",
    "    X_test = test[features].fillna(0)\n",
    "    test_pool = Pool(X_test, cat_features=cat_features)\n",
    "    y_test_pred = model.predict(test_pool)\n",
    "    pred_df = pd.DataFrame({\n",
    "        'store_subgroup_date_id': test['store_subgroup_date_id'],\n",
    "        'demand': y_test_pred\n",
    "    })\n",
    "    kaggle = crear_archivo_kaggle(pred_df)\n",
    "    print('Predicciones realizadas y archivo kaggle creado (prediccion_kaggle.csv)')\n",
    "else:\n",
    "    print('No se generaron predicciones para test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a077dd43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10) Función para calcular elasticidad aproximada por fila\n",
    "def computar_elasticidad(model, row, features, cat_features, price_col='mean_price', deltas=[-0.1, 0.1]):\n",
    "    base = row.copy()\n",
    "    X_base = pd.DataFrame([base[features]]).fillna(0)\n",
    "    q0 = model.predict(Pool(X_base, cat_features=cat_features))[0]\n",
    "    outs = {}\n",
    "    for d in deltas:\n",
    "        r2 = base.copy()\n",
    "        r2[price_col] = base[price_col] * (1 + d)\n",
    "        X2 = pd.DataFrame([r2[features]]).fillna(0)\n",
    "        q2 = model.predict(Pool(X2, cat_features=cat_features))[0]\n",
    "        elast = ((q2 - q0) / q0) / d if q0 != 0 else np.nan\n",
    "        outs[d] = {'price': r2[price_col], 'q_pred': q2, 'elasticity': elast}\n",
    "    return outs\n",
    "\n",
    "# Calcular elasticidad para las primeras 20 filas del test y guardarlas\n",
    "elastic_results = []\n",
    "if model is not None and test is not None:\n",
    "    for i in range(min(20, len(test))):\n",
    "        r = test.iloc[i].to_dict()\n",
    "        er = computar_elasticidad(model, r, features, cat_features, deltas=[-0.05, -0.1, 0.05, 0.1])\n",
    "        elastic_results.append({'id': test.iloc[i]['store_subgroup_date_id'], 'elastic': er})\n",
    "    # Guardar\n",
    "    import json\n",
    "    with open('elastic_results_sample.json','w') as f:\n",
    "        json.dump(elastic_results, f, indent=2)\n",
    "    print('Elasticidades calculadas (muestra) y guardadas en elastic_results_sample.json')\n",
    "else:\n",
    "    print('No se calcularon elasticidades')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
